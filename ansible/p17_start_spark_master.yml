---
# Playbook 22: Start Spark Master
# This playbook stops any running Spark master processes, cleans up the Spark work directory,
# and starts the Spark master process on the management node.

- name: Notify user about Playbook 22
  hosts: localhost
  tasks:
    - name: Display playbook message
      ansible.builtin.debug:
        msg: "Running Playbook 22: Start Spark Master - This playbook stops existing Spark master processes, cleans up the work directory, and starts the Spark master process on the management node."

- name: Start Spark master
  hosts: management
  tasks:
    # Step 1: Stop any running Spark master processes
    - name: Stop any running Spark master processes
      # Find and terminate any Spark master processes currently running.
      ansible.builtin.shell: |
        pid=$(ps aux | grep '[o]rg.apache.spark.deploy.master.Master' | awk '{print $2}')
        if [ -n "$pid" ]; then
          kill -9 $pid
        fi
      ignore_errors: true  # Ignore errors if no process is found.

    # Step 2: Clean Spark work directory
    - name: Clean Spark work directory
      # Remove the Spark work directory to ensure a clean state before starting the Spark master.
      ansible.builtin.file:
        path: /home/almalinux/spark-3.5.3-bin-hadoop3-scala2.13/work/
        state: absent

    # Step 3: Start Spark master process
    - name: Start Spark master
      # Start the Spark master process using the provided script.
      ansible.builtin.shell: /home/almalinux/spark-3.5.3-bin-hadoop3-scala2.13/sbin/start-master.sh